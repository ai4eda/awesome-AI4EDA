@inproceedings{ISCA22_sns,
  title     = {SNS's Not a Synthesizer: A Deep-Learning-Based Synthesis Predictor},
  author    = {Xu, Ceyu and Kjellqvist, Chris and Wills, Lisa Wu},
  booktitle = {Proceedings of the 49th Annual International Symposium on Computer Architecture (\textbf{ISCA '22})},
  _venue    = {ISCA},
  year      = {2022},
  topic     = {Synthesis Results Estimation},
  url       = {https://doi.org/10.1145/3470496.3527444},
  abstract  = {The number of transistors that can fit on one monolithic chip has reached billions to tens of billions in this decade thanks to Moore's Law. With the advancement of every technology generation, the transistor counts per chip grow at a pace that brings about exponential increase in design time, including the synthesis process used to perform design space explorations. Such a long delay in obtaining synthesis results hinders an efficient chip development process, significantly impacting time-to-market. In addition, these large-scale integrated circuits tend to have larger and higher-dimension design spaces to explore, making it prohibitively expensive to obtain physical characteristics of all possible designs using traditional synthesis tools.In this work, we propose a deep-learning-based synthesis predictor called SNS (SNS's not a Synthesizer), that predicts the area, power, and timing physical characteristics of a broad range of designs at two to three orders of magnitude faster than the Synopsys Design Compiler while providing on average a 0.4998 RRSE (root relative square error). We further evaluate SNS via two representative case studies, a general-purpose out-of-order CPU case study using RISC-V Boom open-source design and an accelerator case study using an in-house Chisel implementation of DianNao, to demonstrate the capabilities and validity of SNS.},
  code_url  = {https://github.com/Entropy-xcy/sns}
}


@inproceedings{ICCAD20_flowtune,
  title     = {Practical Multi-armed Bandits in Boolean Optimization},
  author    = {Cunxi Yu},
  booktitle = {2020 International Conference On Computer Aided Design (\textbf{ICCAD'20})},
  _venue    = {ICCAD},
  year      = {2020},
  topic     = {Operator Sequence Scheduling},
  url       = {https://doi.org/10.1145/3400302.3415615},
  abstract  = {Recent years have seen increasing employment of decision intelligence in electronic design automation (EDA), which aims to reduce the manual efforts and boost the design closure process in modern toolflows. However, existing approaches either require a large number of labeled data for training or are limited in practical EDA toolflow integration due to computation overhead. This paper presents a generic end-to-end and high-performance domainspecific, multi-stage multi-armed bandit framework for Boolean logic optimization. This framework addresses optimization problems on a) And-Inv-Graphs (# nodes), b) Conjunction Normal Form (CNF) minimization (# clauses) for Boolean Satisfiability, c) post static timing analysis (STA) delay and area optimization for standard-cell technology mapping, and d) FPGA technology mapping for 6-in LUT architectures. Moreover, the proposed framework has been integrated with ABC, Yosys, VTR, and industrial tools. The experimental results demonstrate that our framework outperforms both hand-crafted flows and ML explored flows in quality of results, and is orders of magnitude faster compared to ML-based approaches.},
  code_url  = {https://github.com/Yu-Utah/FlowTune},
  talk_url  = {https://www.youtube.com/watch?v=EPcn5ttp1TM&t=360s}
}

@article{TCAD22_bullseye,
  title     = {Bulls-Eye: Active Few-shot Learning Guided Logic Synthesis},
  author    = {Chowdhury, Animesh Basak and Tan, Benjamin and Carey, Ryan and Jain, Tushit and Karri, Ramesh and Garg, Siddharth},
  booktitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (\textbf{TCAD '22})},
  _venue    = {TCAD},
  year      = {2022},
  topic     = {Synthesis Results Estimation},
  url       = {https://ieeexplore.ieee.org/abstract/document/9969911},
  abstract  = { Generating sub-optimal synthesis transformation sequences (“synthesis recipe”) is an important problem in logic synthesis. Manually crafted synthesis recipes have poor quality. State-of-the art machine learning (ML) works to generate synthesis recipes do not scale to large netlists as the models need to be trained from scratch, for which training data is collected using time consuming synthesis runs. We propose a new approach, Bulls-Eye, that fine-tunes a pre-trained model on past synthesis data to accurately predict the quality of a synthesis recipe for an unseen netlist. Our approach achieves 2x-30x run-time improvement and generates synthesis recipes achieving close to 95\% quality-of-result (QoR) compared to conventional techniques using actual synthesis runs. We show our QoR beat state-of-the-art approaches on various benchmarks.}
}

@inproceedings{ASPDAC20_drills,
  title     = {DRiLLS: Deep Reinforcement Learning for Logic Synthesis},
  author    = {Hosny, Abdelrahman and Hashemi, Soheil and Shalan, Mohamed and Reda, Sherief},
  booktitle = {2020 25th Asia and South Pacific Design Automation Conference (\textbf{ASP-DAC '20})},
  _venue    = {ASP-DAC},
  year      = {2020},
  topic     = {Operator Sequence Scheduling},
  url       = {https://ieeexplore.ieee.org/abstract/document/9045559},
  abstract  = {Logic synthesis requires extensive tuning of the synthesis optimization flow where the quality of results (QoR) depends on the sequence of optimizations used. Efficient design space exploration is challenging due to the exponential number of possible optimization permutations. Therefore, automating the optimization process is necessary. In this work, we propose a novel reinforcement learning-based methodology that navigates the optimization space without human intervention. We demonstrate the training of an Advantage Actor Critic (A2C) agent that seeks to minimize area subject to a timing constraint. Using the proposed methodology, designs can be optimized autonomously with no-humans in-loop. Evaluation on the comprehensive EPFL benchmark suite shows that the agent outperforms existing exploration methodologies and improves QoRs by an average of 13\%.},
  code_url  = {https://github.com/scale-lab/DRiLLS}
}

@inproceedings{MLCAD20_decision,
  title     = {Decision making in synthesis cross technologies using LSTMs and transfer learning},
  author    = {Yu, Cunxi and Zhou, Wang},
  booktitle = {Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD (\textbf{MLCAD '20})},
  _venue    = {MLCAD},
  year      = {2020},
  topic     = {Synthesis Results Estimation},
  url       = {https://doi.org/10.1145/3380446.3430638},
  abstract  = {We propose a general approach that precisely estimates the Quality-of-Result (QoR), such as delay and area, of unseen synthesis flows for specific designs. The main idea is leveraging LSTM-based network to forecast the QoR, where the inputs are synthesis flows represented in novel timed-flow modeling, and QoRs are ground truth. This approach is demonstrated with 1.2 million data points collected using 14nm, 7nm regular-voltage (RVT), and 7nm low-voltage (LVT) technologies with twelve IC designs. The accuracy of predicting the QoRs (delay and area) evaluated using mean absolute prediction error (MAPE). While collecting training data points in EDA can be extremely challenging, we propose to elaborate transfer learning in our approach, which enables accurate predictions cross different technologies and different IC designs. Our transfer learning approach obtains estimation MAPE 3.7\% over 960,000 test points collected on 7nm technologies, with only 100 data points used for training the pre-trained LSTM network using 14nm dataset.},
  talk_url  = {https://www.youtube.com/watch?v=c5k1uQahMa8&t=184s}
}

@inproceedings{DAC18_angel,
  title      = {Developing synthesis flows without human knowledge},
  author     = {Yu, Cunxi and Xiao, Houping and De Micheli, Giovanni},
  booktitle  = {Proceedings of the 55th Annual Design Automation Conference (\textbf{DAC '18})},
  _venue     = {DAC},
  year       = {2018},
  topic      = {Synthesis Results Estimation},
  url        = {https://doi.org/10.1145/3195970.3196026},
  abstract   = {Design flows are the explicit combinations of design transformations, primarily involved in synthesis, placement and routing processes, to accomplish the design of Integrated Circuits (ICs) and System-on-Chip (SoC). Mostly, the flows are developed based on the knowledge of the experts. However, due to the large search space of design flows and the increasing design complexity, developing Intellectual Property (IP)-specific synthesis flows providing high Quality of Result (QoR) is extremely challenging. This work presents a fully autonomous framework that artificially produces design-specific synthesis flows without human guidance and baseline flows, using Convolutional Neural Network (CNN). The demonstrations are made by successfully designing logic synthesis flows of three large scaled designs.},
  code_url   = {https://github.com/ycunxi/FLowGen-CNNs-DAC18},
  slides_url = {https://ycunxi.github.io/cunxiyu/slides/dac18.pdf}
}

@inproceedings{DBLP:conf/iccad/FengLCYYH22,
  author    = {Chang Feng and Wenlong Lyu and Zhitang Chen and Junjie Ye and Mingxuan Yuan and Jianye Hao},
  editor    = {Tulika Mitra and Evangeline F. Y. Young and Jinjun Xiong},
  title     = {Batch Sequential Black-Box Optimization with Embedding Alignment Cells for Logic Synthesis},
  booktitle = {Proceedings of the 41st {IEEE/ACM} International Conference on Computer-Aided Design, {ICCAD} 2022, San Diego, California, USA, 30 October 2022 - 3 November 2022},
  pages     = {56:1--56:9},
  publisher = {{ACM}},
  year      = {2022},
  url       = {https://doi.org/10.1145/3508352.3549363},
  doi       = {10.1145/3508352.3549363},
  _venue    = {ICCAD}
}




@inproceedings{LS_MLCAD20_Zhu,
  author    = {Zhu, Keren and Liu, Mingjie and Chen, Hao and Zhao, Zheng and Pan, David Z.},
  booktitle = {2020 ACM/IEEE 2nd Workshop on Machine Learning for CAD (MLCAD)},
  _venue    = {MLCAD},
  title     = {Exploring Logic Optimizations with Reinforcement Learning and Graph Convolutional Network},
  year      = {2020},
  url       = {https://ieeexplore.ieee.org/document/9394650},
}
